{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "import xgboost as xgb\n",
    "import matplotlib.animation as animation\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import the BaseAgent class\n",
    "from src.agents.base_agent import BaseAgent\n",
    "from initial_windfields import get_initial_windfield, INITIAL_WINDFIELDS\n",
    "from src.env_sailing import SailingEnv\n",
    "from src.test_agent_validity import validate_agent, load_agent_class\n",
    "from src.evaluation import evaluate_agent, visualize_trajectory\n",
    "\n",
    "# Environment parameters\n",
    "env = SailingEnv(**get_initial_windfield('simple_static'))\n",
    "n_actions = env.action_space.n\n",
    "d_s = 2054"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the playing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_animation(imgs):\n",
    "  \"\"\"\n",
    "  Makes an animation from a list of images\n",
    "  Parameters\n",
    "  ----------\n",
    "  imgs: list of (height, width, 3) np arrays\n",
    "    list of images\n",
    "  Return\n",
    "  -------\n",
    "  ani: animation\n",
    "  \"\"\"\n",
    "  fig, ax = plt.subplots()\n",
    "  draw = []\n",
    "  for i in range(len(imgs)):\n",
    "    draw_i = ax.imshow(imgs[i])\n",
    "    if i == 0:\n",
    "      ax.imshow(imgs[0]) # Show an initial one first\n",
    "    draw.append([draw_i])\n",
    "  plt.close()\n",
    "  ani = animation.ArtistAnimation(fig, draw, interval=200, blit=True,\n",
    "                              repeat=False)\n",
    "  return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_policy(env, pi, horizon=200, capture_rate=1):\n",
    "  s, _ = env.reset()\n",
    "  a = pi(s)\n",
    "  imgs = []\n",
    "  imgs.append(env.render())\n",
    "  for tt in range(horizon):\n",
    "    s, rew, term, trunc, _ = env.step(a)\n",
    "    a = pi(s)\n",
    "    if tt % capture_rate == 0:\n",
    "      imgs.append(env.render())\n",
    "    if term or trunc:\n",
    "      break\n",
    "  return make_animation(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_1\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.8, -0.2), 'pattern_scale': 32, 'pattern_strength': 0.3, 'strength_variation': 0.4, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}, 'env_params': {'wind_grid_density': 25, 'wind_arrow_scale': 80, 'render_mode': 'rgb_array'}}\n",
      "training_2\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.2, 0.8), 'pattern_scale': 128, 'pattern_strength': 0.6, 'strength_variation': 0.3, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}, 'env_params': {'wind_grid_density': 25, 'wind_arrow_scale': 80, 'render_mode': 'rgb_array'}}\n",
      "training_3\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (0.2, -0.8), 'pattern_scale': 32, 'pattern_strength': 0.4, 'strength_variation': 0.2, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}, 'env_params': {'wind_grid_density': 25, 'wind_arrow_scale': 80, 'render_mode': 'rgb_array'}}\n",
      "simple_static\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.7, -0.7), 'pattern_scale': 32, 'pattern_strength': 0.1, 'strength_variation': 0.1, 'noise': 0.05}, 'wind_evol_params': {'wind_change_prob': 0.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.0, 'perturbation_strength_amplitude': 0.0, 'rotation_bias': 0.0, 'bias_strength': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "for initial_windfield_name, initial_windfield in INITIAL_WINDFIELDS.items():\n",
    "    print(initial_windfield_name)\n",
    "    print(initial_windfield)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted Q iteration\n",
    "\n",
    ">Implement fitted Q iterations with random forest using uniform exploration for $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a dataset \n",
    "\n",
    "def collect_dataset(pi= lambda x: np.random.randint(0, n_actions) , n=10000):\n",
    "    \"\"\"\n",
    "    Collect a dataset of the form $(s_i, a_i, r_{a_i}(s_i), s'_i)_{i=1}^n$\n",
    "    by running a policy that chooses its action uniformly at random\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    env: Environment\n",
    "    pi: Policy\n",
    "    n: int\n",
    "        Number of samples to collect\n",
    "\n",
    "    Return\n",
    "    -----\n",
    "    data: np array of size (n, 2d_s + d_a + 2)\n",
    "        data collected by the random policy\n",
    "        the first 4 columns are the states s_i,\n",
    "        the 5th, 6th and 7th columns contain the actions a_i,\n",
    "        rewards r_{a_i}(s_i) and whether the step is a termination step\n",
    "        and the columns 8th-12th columns contain the states s'_i\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for initial_windfield_name, initial_windfield in INITIAL_WINDFIELDS.items():\n",
    "        print(initial_windfield_name)\n",
    "        env = SailingEnv(**get_initial_windfield(initial_windfield_name))\n",
    "        s0, _ = env.reset()\n",
    "        s = s0.copy()\n",
    "        n_actions = env.action_space.n\n",
    "\n",
    "        for i in range(n//4):\n",
    "            a = pi(s)\n",
    "            s2, r, done, trunc, _ = env.step(a)\n",
    "            data.append(s.copy().tolist() + [a, r, done] + s2.copy().tolist())\n",
    "            if done or trunc:\n",
    "                s, _ = env.reset()\n",
    "            else:\n",
    "                s = s2.copy()\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('training_1', {'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.8, -0.2), 'pattern_scale': 32, 'pattern_strength': 0.3, 'strength_variation': 0.4, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}, 'env_params': {'wind_grid_density': 25, 'wind_arrow_scale': 80, 'render_mode': 'rgb_array'}}), ('training_2', {'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.2, 0.8), 'pattern_scale': 128, 'pattern_strength': 0.6, 'strength_variation': 0.3, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}, 'env_params': {'wind_grid_density': 25, 'wind_arrow_scale': 80, 'render_mode': 'rgb_array'}}), ('training_3', {'wind_init_params': {'base_speed': 3.0, 'base_direction': (0.2, -0.8), 'pattern_scale': 32, 'pattern_strength': 0.4, 'strength_variation': 0.2, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}, 'env_params': {'wind_grid_density': 25, 'wind_arrow_scale': 80, 'render_mode': 'rgb_array'}}), ('simple_static', {'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.7, -0.7), 'pattern_scale': 32, 'pattern_strength': 0.1, 'strength_variation': 0.1, 'noise': 0.05}, 'wind_evol_params': {'wind_change_prob': 0.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.0, 'perturbation_strength_amplitude': 0.0, 'rotation_bias': 0.0, 'bias_strength': 0.0}})])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INITIAL_WINDFIELDS.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SailingEnv.__init__() got an unexpected keyword argument 'env_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = \u001b[43mcollect_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mcollect_dataset\u001b[39m\u001b[34m(pi, n)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m initial_windfield_name, initial_windfield \u001b[38;5;129;01min\u001b[39;00m INITIAL_WINDFIELDS.items():\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(initial_windfield_name)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     env = \u001b[43mSailingEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mget_initial_windfield\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_windfield_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     s0, _ = env.reset()\n\u001b[32m     29\u001b[39m     s = s0.copy()\n",
      "\u001b[31mTypeError\u001b[39m: SailingEnv.__init__() got an unexpected keyword argument 'env_params'"
     ]
    }
   ],
   "source": [
    "data = collect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SailingEnv.__init__() got an unexpected keyword argument 'env_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mFQI\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseAgent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\" FQI agent\"\"\"\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollect_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_s\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2054\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_actions\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mFQI\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFQI\u001b[39;00m(BaseAgent):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" FQI agent\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data=\u001b[43mcollect_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, gamma=\u001b[32m0.99\u001b[39m, n_iterations=\u001b[32m100\u001b[39m, d_s=\u001b[32m2054\u001b[39m, n_actions=\u001b[32m9\u001b[39m):\n\u001b[32m      5\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mself\u001b[39m.d_s = \u001b[32m2054\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mcollect_dataset\u001b[39m\u001b[34m(pi, n)\u001b[39m\n\u001b[32m     24\u001b[39m data = []\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m initial_windfield_name, initial_windfield \u001b[38;5;129;01min\u001b[39;00m INITIAL_WINDFIELDS.items():\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     env = \u001b[43mSailingEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mget_initial_windfield\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_windfield_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     s0, _ = env.reset()\n\u001b[32m     28\u001b[39m     s = s0.copy()\n",
      "\u001b[31mTypeError\u001b[39m: SailingEnv.__init__() got an unexpected keyword argument 'env_params'"
     ]
    }
   ],
   "source": [
    "class FQI(BaseAgent):\n",
    "    \"\"\" FQI agent\"\"\"\n",
    "    \n",
    "    def __init__(self, data=collect_dataset(), gamma=0.99, n_iterations=100, d_s=2054, n_actions=9):\n",
    "        super().__init__()\n",
    "        self.d_s = 2054\n",
    "        self.data = data\n",
    "        self.gamma = gamma \n",
    "        self.n_iterations = n_iterations\n",
    "        self.d_s = d_s \n",
    "        self.n_actions = n_actions\n",
    "        self.epsilon = 0.2\n",
    "        self.model = RandomForestRegressor()\n",
    "        self.pi = None\n",
    "        \n",
    "    \n",
    "    def act(self, observation: np.ndarray) -> int:\n",
    "        if self.pi is None:\n",
    "            print(\"The Agent has not been trained\")\n",
    "        else:\n",
    "            return int(self.pi(observation))\n",
    "    \n",
    "    def trainFQI(self):\n",
    "        # Use the data collected before\n",
    "        n = len(self.data)\n",
    "        states, actions, rewards, dones, next_states = self.data[:, :2054], self.data[:, 2054], self.data[:, 2054+1], self.data[:, 2054+2], self.data[:, 2054+3:]\n",
    "        X, Y = self.data[:, :2054+1], self.data[:, 2054+1]\n",
    "        self.model.fit(X, Y)\n",
    "\n",
    "        for _ in tqdm(range(self.n_iterations)):\n",
    "            Qmax = np.max(\n",
    "                            [\n",
    "                            self.model.predict(np.column_stack([\n",
    "                                            self.data[:, d_s + 3:],\n",
    "                                            np.ones(n).reshape(-1, 1) * a\n",
    "                                            ]))\n",
    "                                for a in range(n_actions)\n",
    "                            ],axis=0)\n",
    "            Y = self.data[:, d_s + 1] + self.gamma * (1 - dones) * Qmax\n",
    "            self.model.fit(X, Y)\n",
    "        \n",
    "        pi = lambda s: np.argmax(\n",
    "                                [self.model.predict(np.array(s.tolist() + [a]).reshape(1, -1))[0] for a in range(n_actions)]\n",
    "                                )\n",
    "        self.pi = pi\n",
    "        agent.save(path=\"models/FQI_RF\")\n",
    "        return pi\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the agent.\"\"\"\n",
    "        pass  # Nothing to reset in this simple agent\n",
    "    \n",
    "    def seed(self, seed: int = None) -> None:\n",
    "        \"\"\"Set the random seed.\"\"\"\n",
    "        self.np_random = np.random.default_rng(seed)\n",
    "\n",
    "    def save(self, path):\n",
    "        if self.model is not None:\n",
    "            joblib.dump(self.model, path)\n",
    "        else:\n",
    "            print(\"No model found to save.\")\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            self.model = joblib.load(\"models/FQI_RF\")\n",
    "        except:\n",
    "            print(\"No saved model found.\")\n",
    "            self.model = None\n",
    "\n",
    "\n",
    "agent = FQI()\n",
    "pi_FQI = agent.trainFQI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating agent on 3 training initial windfields...\n",
      "\n",
      "Initial windfield: training_1\n",
      "  Success Rate: 100.00%\n",
      "  Mean Reward: 28.51\n",
      "  Mean Steps: 127.4\n",
      "\n",
      "Initial windfield: training_2\n",
      "  Success Rate: 80.00%\n",
      "  Mean Reward: 55.17\n",
      "  Mean Steps: 70.4\n",
      "\n",
      "Initial windfield: training_3\n",
      "  Success Rate: 100.00%\n",
      "  Mean Reward: 47.44\n",
      "  Mean Steps: 75.4\n",
      "\n",
      "==================================================\n",
      "OVERALL SUCCESS RATE: 93.33%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Choose which training initial windfields to evaluate on\n",
    "TRAINING_INITIAL_WINDFIELDS = [\"training_1\", \"training_2\", \"training_3\"]\n",
    "\n",
    "# Evaluation parameters for all initial windfields\n",
    "ALL_SEEDS = [42, 43, 44, 45, 46]  # Seeds to use for all evaluations\n",
    "ALL_MAX_HORIZON = 200             # Maximum steps per episode\n",
    "\n",
    "# Only run if the agent was successfully loaded\n",
    "if 'agent' in locals():\n",
    "    # Store results for each initial windfield\n",
    "    all_results = {}\n",
    "    \n",
    "    print(f\"Evaluating agent on {len(TRAINING_INITIAL_WINDFIELDS)} training initial windfields...\")\n",
    "    \n",
    "    # Evaluate on each initial windfield\n",
    "    for initial_windfield_name in TRAINING_INITIAL_WINDFIELDS:\n",
    "        print(f\"\\nInitial windfield: {initial_windfield_name}\")\n",
    "        \n",
    "        # Get the initial windfield\n",
    "        initial_windfield = get_initial_windfield(initial_windfield_name)\n",
    "        \n",
    "        # Run the evaluation\n",
    "        results = evaluate_agent(\n",
    "            agent=agent,\n",
    "            initial_windfield=initial_windfield,\n",
    "            seeds=ALL_SEEDS,\n",
    "            max_horizon=ALL_MAX_HORIZON,\n",
    "            verbose=False,  # Less verbose for multiple evaluations\n",
    "            render=False,\n",
    "            full_trajectory=False\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        all_results[initial_windfield_name] = results\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"  Success Rate: {results['success_rate']:.2%}\")\n",
    "        print(f\"  Mean Reward: {results['mean_reward']:.2f}\")\n",
    "        print(f\"  Mean Steps: {results['mean_steps']:.1f}\")\n",
    "    \n",
    "    # Print overall performance\n",
    "    total_success = sum(r['success_rate'] for r in all_results.values()) / len(all_results)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"OVERALL SUCCESS RATE: {total_success:.2%}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing agent behavior on initial windfield: training_3\n",
      "Using seed: 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10109115e1d24eeb812e0be3397e79b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Step:', max=87), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set to True to enable visualization\n",
    "VISUALIZE = True\n",
    "MAX_HORIZON = 200\n",
    "\n",
    "# Visualization parameters\n",
    "VIZ_INITIAL_WINDFIELD_NAME = \"training_3\"  # Choose which initial windfield to visualize\n",
    "VIZ_SEED = 42                    # Choose a single seed for visualization\n",
    "\n",
    "#############################################\n",
    "### DO NOT MODIFY BELOW THIS LINE ##########\n",
    "#############################################\n",
    "\n",
    "# Only run if visualization is enabled and agent is loaded\n",
    "if VISUALIZE and 'agent' in locals():\n",
    "    # Get the initial windfield with visualization parameters\n",
    "    viz_initial_windfield = get_initial_windfield(VIZ_INITIAL_WINDFIELD_NAME)\n",
    "    viz_initial_windfield.update({\n",
    "        'env_params': {\n",
    "            'wind_grid_density': 25,\n",
    "            'wind_arrow_scale': 80,\n",
    "            'render_mode': \"rgb_array\"\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    print(f\"Visualizing agent behavior on initial windfield: {VIZ_INITIAL_WINDFIELD_NAME}\")\n",
    "    print(f\"Using seed: {VIZ_SEED}\")\n",
    "    \n",
    "    # Run the evaluation with visualization enabled\n",
    "    viz_results = evaluate_agent(\n",
    "        agent=agent,\n",
    "        initial_windfield=viz_initial_windfield,\n",
    "        seeds=VIZ_SEED,\n",
    "        max_horizon=MAX_HORIZON,\n",
    "        verbose=False,\n",
    "        render=True,\n",
    "        full_trajectory=True  # Enable full trajectory for visualization\n",
    "    )\n",
    "    \n",
    "    # Visualize the trajectory with a slider\n",
    "    visualize_trajectory(viz_results, None, with_slider=True)\n",
    "else:\n",
    "    if 'agent' in locals():\n",
    "        print(\"Visualization is disabled. Set VISUALIZE = True to see agent behavior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(BaseAgent):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "    def act(self, observation: np.ndarray) -> int:\n",
    "        \"\"\" \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the agent.\"\"\"\n",
    "        pass  # Nothing to reset in this simple agent\n",
    "    \n",
    "    def seed(self, seed: int = None) -> None:\n",
    "        \"\"\"Set the random seed.\"\"\"\n",
    "        self.np_random = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sailing-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
