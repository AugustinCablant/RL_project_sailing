{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import the BaseAgent class\n",
    "from src.agents.base_agent import BaseAgent\n",
    "from initial_windfields import get_initial_windfield, INITIAL_WINDFIELDS\n",
    "from src.env_sailing import SailingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_1\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.8, -0.2), 'pattern_scale': 32, 'pattern_strength': 0.3, 'strength_variation': 0.4, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}}\n",
      "training_2\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.2, 0.8), 'pattern_scale': 128, 'pattern_strength': 0.6, 'strength_variation': 0.3, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}}\n",
      "training_3\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (0.2, -0.8), 'pattern_scale': 32, 'pattern_strength': 0.4, 'strength_variation': 0.2, 'noise': 0.1}, 'wind_evol_params': {'wind_change_prob': 1.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.1, 'perturbation_strength_amplitude': 0.1, 'rotation_bias': 0.02, 'bias_strength': 1.0}}\n",
      "simple_static\n",
      "{'wind_init_params': {'base_speed': 3.0, 'base_direction': (-0.7, -0.7), 'pattern_scale': 32, 'pattern_strength': 0.1, 'strength_variation': 0.1, 'noise': 0.05}, 'wind_evol_params': {'wind_change_prob': 0.0, 'pattern_scale': 128, 'perturbation_angle_amplitude': 0.0, 'perturbation_strength_amplitude': 0.0, 'rotation_bias': 0.0, 'bias_strength': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "for initial_windfield_name, initial_windfield in INITIAL_WINDFIELDS.items():\n",
    "    print(initial_windfield_name)\n",
    "    print(initial_windfield)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the training loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(agent, initial_windfields=INITIAL_WINDFIELDS.keys(), num_episodes=100, save_path=\"\", verbose=True):\n",
    "    # Setup training parameters\n",
    "    max_steps = 1000\n",
    "    rewards_history = []\n",
    "    steps_history = []\n",
    "    success_history = []\n",
    "    \n",
    "    # Train on multiple initial windfields\n",
    "    start_time = time.time()\n",
    "\n",
    "    for initial_windfield_name, initial_windfield in initial_windfields.items():\n",
    "        # Train agent on this initial_windfields\n",
    "        env = SailingEnv(**get_initial_windfield('initial_windfield_name'))\n",
    "        \n",
    "        # Training loop\n",
    "        if verbose:\n",
    "            print(\"Starting training with 10 episodes (debug run)...\")\n",
    "        for episode in range(num_episodes):\n",
    "            # Reset environment and get initial state\n",
    "            observation, info = env.reset(seed=episode)  # Different seed each episode\n",
    "            \n",
    "            total_reward = 0\n",
    "\n",
    "            for step in range(max_steps):\n",
    "                # Select action and take step\n",
    "                action = agent.act(observation)\n",
    "                next_observation, reward, done, truncated, info = env.step(action)\n",
    "                next_state =  #agent.discretize_state(next_observation)\n",
    "                \n",
    "                # Update \n",
    "                agent.learn(state, action, reward, next_state)\n",
    "                \n",
    "                # Update state and total reward\n",
    "                state = next_state\n",
    "                observation = next_observation\n",
    "                total_reward += reward\n",
    "                # Break if episode is done\n",
    "                if done or truncated:\n",
    "                    break\n",
    "\n",
    "            rewards_history.append(total_reward)\n",
    "            steps_history.append(step+1)\n",
    "            success_history.append(done)\n",
    "            \n",
    "    success_rate = sum(success_history) / len(success_history) * 100\n",
    "    training_time = time.time() - start_time \n",
    "    \n",
    "    # Save the trained agent\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nTraining completed in {training_time:.1f} seconds!\")\n",
    "        print(f\"Success rate: {success_rate:.1f}%\")\n",
    "        print(f\"Average reward: {np.mean(rewards_history):.2f}\")\n",
    "        print(f\"Average steps: {np.mean(steps_history):.1f}\")\n",
    "    \n",
    "    \n",
    "    return training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(BaseAgent):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "    def act(self, observation: np.ndarray) -> int:\n",
    "        \"\"\" \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the agent.\"\"\"\n",
    "        pass  # Nothing to reset in this simple agent\n",
    "    \n",
    "    def seed(self, seed: int = None) -> None:\n",
    "        \"\"\"Set the random seed.\"\"\"\n",
    "        self.np_random = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sailing-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
